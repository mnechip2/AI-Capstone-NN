{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84a94fbb",
   "metadata": {},
   "source": [
    "\n",
    "# Preprocessing & Training\n",
    "\n",
    "## NeuroSense Analytics \n",
    "\n",
    "### v0.1.5\n",
    "\n",
    "#### Planned Features  \n",
    "\n",
    "- Dedicated preprocessor class for LSTM model\n",
    "- LSTM model class for training\n",
    "- Pipelining preprocessing into training\n",
    "- Hyperparameter optimisation using Optuna\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd096230",
   "metadata": {},
   "source": [
    "# Documentation  \n",
    "\n",
    "## DataPreprocessor  \n",
    "\n",
    "Creating a `preprocessor` class to automate the import workflow - preprocessor handles data import, datatype casting, one-hot encoding, MICE imputation, joining feature data with survey data and returns a Polars dataframe or NumPy series.  \n",
    "\n",
    "Output is in the shape of `batch_size`, `time_steps`, `features` for LSTM processing.   \n",
    "\n",
    "> ### Parameters:  \n",
    "\n",
    "- `path`: *`{1, 2, 3, 4}`*  \n",
    "Data path to use (INS_W1 = `1`, INS_W2 = `2`, INS_W3 = `3`, INS_W4 = `4`)  \n",
    "\n",
    "- `imputer_max_iter`: *`int`, default = `10`*  \n",
    "Max amount of iterations for IterativeImputer.  \n",
    "\n",
    "- `imputer_random_state`: *`int`, default = `42`*  \n",
    "Imputer random state.  \n",
    "\n",
    "- `nearest_features`: *`int`, default = `None`*  \n",
    "How many neighbours to sample when imputing.  \n",
    "\n",
    "- `strategy`: *`{‘mean’, ‘median’, ‘most_frequent’, ‘constant’}`, default = `median`*  \n",
    "What strategy to use when imputing  \n",
    "\n",
    "- `impute`: *`bool`, default = `True`*  \n",
    "Whether or not to run imputation.  \n",
    "\n",
    "- `exclude_history`: *`bool`, default = `True`*  \n",
    "Whether or not to exclude 14- and 7-day histories during preprocessing.\n",
    "\n",
    "> ### Functions:  \n",
    "\n",
    "- `import_csv_feature_data(csv)`:  \n",
    "Imports and normalises feature dataset. Returns `pl.DataFrame`.\n",
    "\n",
    "    > Parameters:  \n",
    "\n",
    "    - `csv`: *`str`*   \n",
    "    File name of csv to be processed.  \n",
    "\n",
    "- `import_csv_survey_data(csv)`:  \n",
    "Imports and normalises survey dataset. Returns `pl.DataFrame`. \n",
    "\n",
    "    > Parameters:  \n",
    "\n",
    "    - `csv`: *`str`*  \n",
    "    File name of csv to be processed.  \n",
    "    \n",
    "- `import_dep_endterm()`:  \n",
    "Imports, one-hot encodes and normalises the `dep_endterm` dataset for the selected datapath. Returns `pl.DataFrame`.\n",
    "\n",
    "- `merge_dataframe(dataframe_1, dataframe_2, join_type)`:  \n",
    "Merges two dataframes on `join_type`, returns `pl.DataFrame`.  \n",
    "\n",
    "    > Parameters:  \n",
    "\n",
    "    - `dataframe_1`: *`pl.DataFrame`*  \n",
    "    DataFrame to join with. \n",
    "\n",
    "    - `dataframe-2`: *`pl.DataFrame`*  \n",
    "    DataFrame to be joined to `dataframe_1`.  \n",
    "\n",
    "    - `join_type`: *`{‘inner’, ‘left’, ‘right’, ‘full’, ‘semi’, ‘anti’, ‘cross’}, default=\"inner\"`*  \n",
    "    Join strategy.\n",
    "    \n",
    "\n",
    "> ### Example Usage:   \n",
    "\n",
    "`preprocessor_INS_W1 = DataPreprocessor(1, imputer_max_iter=20)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154a7596",
   "metadata": {},
   "source": [
    "## PreprocessorLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919bf80d",
   "metadata": {},
   "source": [
    "## ModelTraining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd577330",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42378d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "from datetime import date\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32bde1d",
   "metadata": {},
   "source": [
    "# Class Declaration  \n",
    "\n",
    "## DataPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31a9029b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script imports CSV files containing feature and survey data, processes them, and prepares them for analysis.\n",
    "# It also includes functions to load and preprocess the data, including scaling and encoding categorical variables.\n",
    "\n",
    "# data path for the CSV files\n",
    "# The data is organized into four directories, each containing feature and survey data.\n",
    "\n",
    "class DataPreprocessor:\n",
    "    def __init__(self, path: str, imputer_max_iter: int = 10, imputer_random_state: int = 42, nearest_features: int = None, strategy: str = \"mean\", only_history: bool = True, impute: bool = True): # Initialize the DataPreprocessor class\n",
    "        self.only_history = only_history # Include only history data if specified\n",
    "        self.scaler = MinMaxScaler() # Initialize the MinMaxScaler with specified parameters\n",
    "        self.impute = impute\n",
    "        self.imputer = IterativeImputer(max_iter=imputer_max_iter, random_state=imputer_random_state, n_nearest_features=nearest_features, initial_strategy=strategy) # Initialize the IterativeImputer with specified parameters\n",
    "\n",
    "        match path: ## Set the path based on the input parameter\n",
    "            case 1:\n",
    "                self.path = \"./csv_data/INS-W_1/\"\n",
    "            case 2:\n",
    "                self.path = \"./csv_data/INS-W_2/\"\n",
    "            case 3:\n",
    "                self.path = \"./csv_data/INS-W_3/\"\n",
    "            case 4:\n",
    "                self.path = \"./csv_data/INS-W_4/\"\n",
    "            case _:\n",
    "                raise ValueError(\"Invalid path specified. Please choose a valid path (1, 2, 3, or 4).\")\n",
    "\n",
    "    # Load the CSV files, cast columns to appropriate types, and drop empty columns\n",
    "    def import_csv_feature_data(self, file_name: str) -> pl.DataFrame:\n",
    "        try:\n",
    "            q = (\n",
    "                pl.scan_csv(self.path + \"FeatureData/\" + file_name + \".csv\")\n",
    "                .select(pl.col(\"*\"))\n",
    "                .cast({\"date\": pl.Date})\n",
    "                .drop(\"\")\n",
    "                .with_columns(pl.col(\"pid\").str.replace_all(\"INS-W_\",\"\"))\n",
    "                .cast({\"pid\": pl.Int32})\n",
    "                .select(pl.exclude(pl.String))\n",
    "            )\n",
    "            data = q.collect() # Collect the lazy frame into a DataFrame\n",
    "\n",
    "            if self.impute:\n",
    "                if self.only_history: # If only history data is to be included\n",
    "                    data = data.select(pl.col([\"pid\",\"date\",\"^.*14dhist$\",\"^.*7dhist$\"]))\n",
    "                scaled_data = pl.from_numpy( # Convert to numpy array for scaling\n",
    "                        self.scaler.fit_transform(data.select(pl.exclude([pl.Date, pl.Int32]))), schema=data.select(pl.exclude([pl.Date, pl.Int32])).columns # min max scaling on all columns except date and pid\n",
    "                    )\n",
    "                try:\n",
    "                    self.imputer.fit(scaled_data) # Fit the imputer to the scaled data\n",
    "                    imputed_data = pl.from_numpy(\n",
    "                        self.imputer.transform(scaled_data), schema=data.select(pl.exclude([\"pid\",\"date\"])).columns # Transform the scaled data using the imputer\n",
    "                    )\n",
    "                    data = data.select([\"pid\",\"date\"])\n",
    "                    data = data.hstack(imputed_data) # Add imputed data back to the DataFrame\n",
    "                    del imputed_data # Delete the imputed data variable to free up memory\n",
    "                except: \n",
    "                    print(\"Error in imputation, returning scaled data without imputation.\")\n",
    "                    return data\n",
    "                return data\n",
    "            return data\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error importing feature data from {self.path + 'FeatureData/' + file_name}: {e}\")\n",
    "            return pl.DataFrame()\n",
    "\n",
    "    def import_csv_survey_data(self, file_name: str) -> pl.DataFrame:\n",
    "        try: # Load survey data from CSV file\n",
    "            q = (\n",
    "                pl.scan_csv(self.path + \"SurveyData/\" + file_name + \".csv\")\n",
    "                .select(pl.col(\"*\"))\n",
    "                .cast({\"date\": pl.Date})\n",
    "                .drop(\"\")\n",
    "                .with_columns(pl.col(\"pid\").str.replace_all(\"INS-W_\",\"\"))\n",
    "                .cast({\"pid\": pl.Int32})\n",
    "            )\n",
    "            data = q.collect()\n",
    "            match file_name:\n",
    "                case \"ema\":\n",
    "                    survey_data = data.select(pl.exclude([\"pid\",\"date\"])) # Convert to numpy array for scaling\n",
    "                    scaled_data = pl.from_numpy(\n",
    "                        self.scaler.fit_transform(survey_data), schema=survey_data.columns\n",
    "                    )\n",
    "                    data = data.select([\"pid\",\"date\"])\n",
    "                    data = data.hstack(scaled_data)\n",
    "                    del scaled_data\n",
    "                    return data\n",
    "                case \"post\":\n",
    "                    survey_data = data.select(pl.exclude([\"pid\",\"date\"])) # Convert to numpy array for scaling\n",
    "                    scaled_data = pl.from_numpy(\n",
    "                        self.scaler.fit_transform(survey_data), schema=survey_data.columns\n",
    "                    )\n",
    "                    data = data.select([\"pid\",\"date\"])\n",
    "                    data = data.hstack(scaled_data)\n",
    "                    del scaled_data\n",
    "                    return data\n",
    "                case \"pre\":\n",
    "                    survey_data = data.select(pl.exclude([\"pid\",\"date\"]))\n",
    "                    scaled_data = pl.from_numpy(\n",
    "                        self.scaler.fit_transform(survey_data), schema=survey_data.columns\n",
    "                    )\n",
    "                    data = data.select([\"pid\",\"date\"])\n",
    "                    data = data.hstack(scaled_data)\n",
    "                    del scaled_data\n",
    "                    return data\n",
    "        except Exception as e:\n",
    "            print(f\"Error importing survey data from {self.path + 'SurveyData/' + file_name}: {e}\")\n",
    "            return pl.DataFrame()\n",
    "\n",
    "    def import_dep_endterm(self) -> pl.DataFrame:\n",
    "        try:\n",
    "            q = (\n",
    "                pl.scan_csv(self.path + \"SurveyData/dep_endterm.csv\")\n",
    "                .select(pl.col(\"*\"))\n",
    "                .cast({\"date\": pl.Date})\n",
    "                .drop(\"\")\n",
    "                .with_columns(pl.col(\"pid\").str.replace_all(\"INS-W_\",\"\"))\n",
    "                .cast({\"pid\": pl.Int32})    \n",
    "                )\n",
    "            data = q.collect()\n",
    "            bdi2 = data.select(pl.exclude([\"pid\",\"date\", \"dep\"]))\n",
    "            data_scaled = pl.from_numpy(\n",
    "                self.scaler.fit_transform(bdi2), schema=bdi2.columns # min max scaling on all columns except date and pid\n",
    "            )\n",
    "            data = data.select([\"pid\",\"date\", \"dep\"])\n",
    "            data = data.hstack(data_scaled) # Add scaled data back to the DataFrame\n",
    "            del data_scaled # Delete the scaled data variable to free up memory\n",
    "            data = data.to_dummies(\"dep\")\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"Error importing endterm data from {self.path + 'SurveyData/dep_endterm.csv'}: {e}\")\n",
    "            return pl.DataFrame()\n",
    "\n",
    "    def merge_dataframe(self, dataframe_1: pl.DataFrame, dataframe_2: pl.DataFrame, join_type: str = \"inner\") -> pl.DataFrame:\n",
    "        try:\n",
    "            merged_data = dataframe_1.join(dataframe_2, on=[\"pid\", \"date\"], how=join_type) # Merge feature and survey data on 'pid'\n",
    "            return merged_data\n",
    "        except Exception as e:\n",
    "            print(f\"Error merging feature and survey data: {e}\")\n",
    "            return pl.DataFrame()\n",
    "    \n",
    "    def import_dep_weekly(self) -> pl.DataFrame:\n",
    "        try:\n",
    "            q = (\n",
    "                pl.scan_csv(self.path + \"SurveyData/dep_weekly.csv\")\n",
    "                .select(pl.col(\"*\"))\n",
    "                .cast({\"date\": pl.Date})\n",
    "                .drop(\"\")\n",
    "                .with_columns(pl.col(\"pid\").str.replace_all(\"INS-W_\",\"\"))\n",
    "                .cast({\"pid\": pl.Int32})\n",
    "                .select(pl.col([\"pid\",\"date\",\"dep_weeklysubscale_endterm_merged\"]))\n",
    "                )\n",
    "            data = q.collect()\n",
    "            data = data.to_dummies(\"dep_weeklysubscale_endterm_merged\") # Convert categorical variable to dummy variables\n",
    "            return data\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error importing weekly data from {self.path + 'SurveyData/dep_weekly.csv'}: {e}\")\n",
    "            return pl.DataFrame()\n",
    "        \n",
    "    def merge_on_date(self, dataframe_1: pl.DataFrame, dataframe_2: pl.DataFrame) -> pl.DataFrame:\n",
    "        try:\n",
    "            merged_data = dataframe_1.join(dataframe_2, on=[\"date\"], how=\"inner\") # Merge feature and survey data on 'date'\n",
    "            return merged_data\n",
    "        except Exception as e:\n",
    "            print(f\"Error merging dataframes on date: {e}\")\n",
    "            return pl.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc89b54",
   "metadata": {},
   "source": [
    "## ModelLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8784f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Masking\n",
    "\n",
    "class ModelLSTM:\n",
    "    def __init__(self): # Initialize the PreprocessorLSTM class\n",
    "        self.logger = logging.getLogger(__name__) # Initialize the logger for the PreprocessorLSTM class\n",
    "        logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s') # Set the logging level and format\n",
    "        self.logger.info(\"PreprocessorLSTM initialized\") # Log the initialization of the PreprocessorLSTM class\n",
    "        self.padded_sequences = None # Initialize the padded sequences variable\n",
    "\n",
    "        \n",
    "    def select_features(self, data: pl.DataFrame, features: list) -> pl.DataFrame:\n",
    "        try:\n",
    "            selected_data = data.select(pl.col(features)) # Select specified features from the DataFrame\n",
    "            self.logger.info(f\"Selected features: {features}\")\n",
    "            return selected_data\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error selecting features: {e}\")\n",
    "            return pl.DataFrame()\n",
    "\n",
    "\n",
    "    def create_padded_sequences(self, data: pl.DataFrame) -> np.ndarray:\n",
    "        self.sequences = data.rows()\n",
    "        try:\n",
    "            self.padded_sequences = pad_sequences(\n",
    "                self.sequences, padding='post', dtype='float32'\n",
    "            )\n",
    "            self.logger.info(f\"Created padded sequences with shape: {self.padded_sequences.shape}\")\n",
    "            return self.padded_sequences\n",
    "        \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error creating padded sequences: {e}\")\n",
    "            return np.array([])\n",
    "    \n",
    "\n",
    "    def split_data(self, padded_sequences: np.ndarray, test_size: float = 0.2) -> tuple:\n",
    "        try:\n",
    "            self.participant_ids = np.arange(len(padded_sequences))  # [0, 1, 2, ...]\n",
    "            self.train_ids, test_ids = train_test_split(self.participant_ids, test_size=test_size, shuffle=False) # Split the data into training and testing sets\n",
    "            self.X_train = padded_sequences[self.train_ids]\n",
    "            self.X_test = padded_sequences[test_ids]\n",
    "            self.y_train = np.array([seq[1:, :] for seq in self.X_train])  # Shift by 1 time step\n",
    "            self.y_test = np.array([seq[1:, :] for seq in self.X_test])\n",
    "            # Logging\n",
    "            self.logger.info(f\"Split data into train and test sets with sizes: {len(self.X_train)}, {len(self.X_test)}\")\n",
    "            self.logger.info(f\"Train and test data shapes: {self.X_train.shape}, {self.X_test.shape}\")\n",
    "            self.logger.info(f\"Train and test labels shapes: {self.y_train.shape}, {self.y_test.shape}\")\n",
    "            return self.X_train, self.X_test, self.y_train, self.y_test\n",
    "        \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error splitting data: {e}\")\n",
    "            return None, None, None, None\n",
    "    \n",
    "    \n",
    "    def build_lstm_model(self, n_features):\n",
    "        try:\n",
    "            inputs = Input(shape=(None, n_features))  # Variable-length sequences\n",
    "            x = Masking(mask_value=0.0)(inputs)      # Ignore padded zeros\n",
    "            x = LSTM(64, return_sequences=True)(x)  # Process entire sequence\n",
    "            outputs = Dense(n_features)(x)           # Predict all features\n",
    "            model = Model(inputs, outputs)\n",
    "            model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "            self.logger.info(\"LSTM model built successfully\")\n",
    "            self.logger.info(f\"Model summary: {model.summary()}\")\n",
    "            return model\n",
    "        \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error building LSTM model: {e}\")\n",
    "            return None\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17c9451",
   "metadata": {},
   "outputs": [],
   "source": [
    "TestModel = ModelLSTM() # Create an instance of the ModelLSTM class\n",
    "model = TestModel.build_lstm_model(n_features=2)\n",
    "model.fit(TestModel.X_train, TestModel.y_train, epochs=10, validation_data=(TestModel.X_test, TestModel.y_test)) # Since x_train and y_train are initialized in the class we can use them directly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425fef18",
   "metadata": {},
   "source": [
    "# INS-W_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "de086055",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 10:47:43,105 - INFO - PreprocessorLSTM initialized\n"
     ]
    }
   ],
   "source": [
    "PreprocessorLSTM = PreprocessorLSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eb2e65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_INS_W1 = DataPreprocessor(1, imputer_max_iter=10, nearest_features=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa3fb42",
   "metadata": {},
   "source": [
    "# Testing, ignore this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30ce1915",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\darkenral\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:895: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rapids_1 = preprocessor_INS_W1.import_csv_feature_data(\"rapids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a8ac1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_weekly_1 = preprocessor_INS_W1.import_dep_weekly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5333ab1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>pid</th><th>date</th><th>dep_weeklysubscale_endterm_merged_false</th><th>dep_weeklysubscale_endterm_merged_true</th></tr><tr><td>i32</td><td>date</td><td>u8</td><td>u8</td></tr></thead><tbody><tr><td>20</td><td>2018-05-09</td><td>1</td><td>0</td></tr><tr><td>198</td><td>2018-04-18</td><td>1</td><td>0</td></tr><tr><td>168</td><td>2018-05-13</td><td>1</td><td>0</td></tr><tr><td>163</td><td>2018-05-20</td><td>1</td><td>0</td></tr><tr><td>44</td><td>2018-05-02</td><td>1</td><td>0</td></tr><tr><td>121</td><td>2018-05-13</td><td>1</td><td>0</td></tr><tr><td>177</td><td>2018-05-30</td><td>1</td><td>0</td></tr><tr><td>13</td><td>2018-04-18</td><td>1</td><td>0</td></tr><tr><td>38</td><td>2018-04-11</td><td>0</td><td>1</td></tr><tr><td>44</td><td>2018-04-04</td><td>1</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 4)\n",
       "┌─────┬────────────┬─────────────────────────────────┬─────────────────────────────────┐\n",
       "│ pid ┆ date       ┆ dep_weeklysubscale_endterm_mer… ┆ dep_weeklysubscale_endterm_mer… │\n",
       "│ --- ┆ ---        ┆ ---                             ┆ ---                             │\n",
       "│ i32 ┆ date       ┆ u8                              ┆ u8                              │\n",
       "╞═════╪════════════╪═════════════════════════════════╪═════════════════════════════════╡\n",
       "│ 20  ┆ 2018-05-09 ┆ 1                               ┆ 0                               │\n",
       "│ 198 ┆ 2018-04-18 ┆ 1                               ┆ 0                               │\n",
       "│ 168 ┆ 2018-05-13 ┆ 1                               ┆ 0                               │\n",
       "│ 163 ┆ 2018-05-20 ┆ 1                               ┆ 0                               │\n",
       "│ 44  ┆ 2018-05-02 ┆ 1                               ┆ 0                               │\n",
       "│ 121 ┆ 2018-05-13 ┆ 1                               ┆ 0                               │\n",
       "│ 177 ┆ 2018-05-30 ┆ 1                               ┆ 0                               │\n",
       "│ 13  ┆ 2018-04-18 ┆ 1                               ┆ 0                               │\n",
       "│ 38  ┆ 2018-04-11 ┆ 0                               ┆ 1                               │\n",
       "│ 44  ┆ 2018-04-04 ┆ 1                               ┆ 0                               │\n",
       "└─────┴────────────┴─────────────────────────────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dep_weekly_1.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb4d8e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "rapids_weekly = dep_weekly_1.join(rapids_1, on=[\"pid\",\"date\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7a4afba",
   "metadata": {},
   "outputs": [],
   "source": [
    "rapids_weekly_float = rapids_weekly.select(pl.exclude(pl.Date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4776a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 819)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>pid</th><th>dep_weeklysubscale_endterm_merged_false</th><th>dep_weeklysubscale_endterm_merged_true</th><th>f_slp:fitbit_sleep_summary_rapids_sumdurationafterwakeupmain:14dhist</th><th>f_slp:fitbit_sleep_summary_rapids_sumdurationasleepmain:14dhist</th><th>f_slp:fitbit_sleep_summary_rapids_sumdurationawakemain:14dhist</th><th>f_slp:fitbit_sleep_summary_rapids_sumdurationtofallasleepmain:14dhist</th><th>f_slp:fitbit_sleep_summary_rapids_sumdurationinbedmain:14dhist</th><th>f_slp:fitbit_sleep_summary_rapids_avgefficiencymain:14dhist</th><th>f_slp:fitbit_sleep_summary_rapids_avgdurationafterwakeupmain:14dhist</th><th>f_slp:fitbit_sleep_summary_rapids_avgdurationasleepmain:14dhist</th><th>f_slp:fitbit_sleep_summary_rapids_avgdurationawakemain:14dhist</th><th>f_slp:fitbit_sleep_summary_rapids_avgdurationtofallasleepmain:14dhist</th><th>f_slp:fitbit_sleep_summary_rapids_avgdurationinbedmain:14dhist</th><th>f_slp:fitbit_sleep_summary_rapids_countepisodemain:14dhist</th><th>f_slp:fitbit_sleep_summary_rapids_firstbedtimemain:14dhist</th><th>f_slp:fitbit_sleep_summary_rapids_lastbedtimemain:14dhist</th><th>f_slp:fitbit_sleep_summary_rapids_firstwaketimemain:14dhist</th><th>f_slp:fitbit_sleep_summary_rapids_lastwaketimemain:14dhist</th><th>f_slp:fitbit_sleep_intraday_rapids_avgdurationasleepunifiedmain:14dhist</th><th>f_slp:fitbit_sleep_intraday_rapids_avgdurationawakeunifiedmain:14dhist</th><th>f_slp:fitbit_sleep_intraday_rapids_maxdurationasleepunifiedmain:14dhist</th><th>f_slp:fitbit_sleep_intraday_rapids_maxdurationawakeunifiedmain:14dhist</th><th>f_slp:fitbit_sleep_intraday_rapids_sumdurationasleepunifiedmain:14dhist</th><th>f_slp:fitbit_sleep_intraday_rapids_sumdurationawakeunifiedmain:14dhist</th><th>f_slp:fitbit_sleep_intraday_rapids_countepisodeasleepunifiedmain:14dhist</th><th>f_slp:fitbit_sleep_intraday_rapids_countepisodeawakeunifiedmain:14dhist</th><th>f_slp:fitbit_sleep_intraday_rapids_stddurationasleepunifiedmain:14dhist</th><th>f_slp:fitbit_sleep_intraday_rapids_stddurationawakeunifiedmain:14dhist</th><th>f_slp:fitbit_sleep_intraday_rapids_mindurationasleepunifiedmain:14dhist</th><th>f_slp:fitbit_sleep_intraday_rapids_mindurationawakeunifiedmain:14dhist</th><th>f_slp:fitbit_sleep_intraday_rapids_mediandurationasleepunifiedmain:14dhist</th><th>f_slp:fitbit_sleep_intraday_rapids_mediandurationawakeunifiedmain:14dhist</th><th>f_slp:fitbit_sleep_intraday_rapids_ratiocountasleepunifiedwithinmain:14dhist</th><th>f_slp:fitbit_sleep_intraday_rapids_ratiocountawakeunifiedwithinmain:14dhist</th><th>f_slp:fitbit_sleep_intraday_rapids_ratiodurationasleepunifiedwithinmain:14dhist</th><th>f_slp:fitbit_sleep_intraday_rapids_ratiodurationawakeunifiedwithinmain:14dhist</th><th>&hellip;</th><th>f_loc:phone_locations_barnett_probpause_norm:7dhist</th><th>f_loc:phone_locations_barnett_rog_norm:7dhist</th><th>f_loc:phone_locations_barnett_siglocentropy_norm:7dhist</th><th>f_loc:phone_locations_barnett_siglocsvisited_norm:7dhist</th><th>f_loc:phone_locations_barnett_stdflightdur_norm:7dhist</th><th>f_loc:phone_locations_barnett_stdflightlen_norm:7dhist</th><th>f_loc:phone_locations_barnett_wkenddayrtn_norm:7dhist</th><th>f_loc:phone_locations_doryab_avglengthstayatclusters_norm:7dhist</th><th>f_loc:phone_locations_doryab_avgspeed_norm:7dhist</th><th>f_loc:phone_locations_doryab_homelabel_norm:7dhist</th><th>f_loc:phone_locations_doryab_locationentropy_norm:7dhist</th><th>f_loc:phone_locations_doryab_locationvariance_norm:7dhist</th><th>f_loc:phone_locations_doryab_loglocationvariance_norm:7dhist</th><th>f_loc:phone_locations_doryab_maxlengthstayatclusters_norm:7dhist</th><th>f_loc:phone_locations_doryab_minlengthstayatclusters_norm:7dhist</th><th>f_loc:phone_locations_doryab_movingtostaticratio_norm:7dhist</th><th>f_loc:phone_locations_doryab_normalizedlocationentropy_norm:7dhist</th><th>f_loc:phone_locations_doryab_numberlocationtransitions_norm:7dhist</th><th>f_loc:phone_locations_doryab_numberofsignificantplaces_norm:7dhist</th><th>f_loc:phone_locations_doryab_outlierstimepercent_norm:7dhist</th><th>f_loc:phone_locations_doryab_radiusgyration_norm:7dhist</th><th>f_loc:phone_locations_doryab_stdlengthstayatclusters_norm:7dhist</th><th>f_loc:phone_locations_doryab_timeathome_norm:7dhist</th><th>f_loc:phone_locations_doryab_timeattop1location_norm:7dhist</th><th>f_loc:phone_locations_doryab_timeattop2location_norm:7dhist</th><th>f_loc:phone_locations_doryab_timeattop3location_norm:7dhist</th><th>f_loc:phone_locations_doryab_totaldistance_norm:7dhist</th><th>f_loc:phone_locations_doryab_varspeed_norm:7dhist</th><th>f_loc:phone_locations_locmap_duration_in_locmap_study_norm:7dhist</th><th>f_loc:phone_locations_locmap_percent_in_locmap_study_norm:7dhist</th><th>f_loc:phone_locations_locmap_duration_in_locmap_exercise_norm:7dhist</th><th>f_loc:phone_locations_locmap_percent_in_locmap_exercise_norm:7dhist</th><th>f_loc:phone_locations_locmap_duration_in_locmap_greens_norm:7dhist</th><th>f_loc:phone_locations_locmap_percent_in_locmap_greens_norm:7dhist</th><th>f_wifi:phone_wifi_connected_rapids_countscans_norm:7dhist</th><th>f_wifi:phone_wifi_connected_rapids_uniquedevices_norm:7dhist</th><th>f_wifi:phone_wifi_connected_rapids_countscansmostuniquedevice_norm:7dhist</th></tr><tr><td>i32</td><td>u8</td><td>u8</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>1</td><td>1</td><td>0</td><td>0.0</td><td>0.093041</td><td>0.016954</td><td>0.0</td><td>0.092651</td><td>0.867925</td><td>0.0</td><td>0.490092</td><td>0.097161</td><td>0.0</td><td>0.509579</td><td>0.133333</td><td>0.664553</td><td>0.687161</td><td>0.713582</td><td>0.603806</td><td>0.123021</td><td>0.140463</td><td>0.253021</td><td>0.124989</td><td>0.11734</td><td>0.021833</td><td>0.271134</td><td>0.017449</td><td>0.144736</td><td>0.1521</td><td>0.026507</td><td>0.10324</td><td>0.043685</td><td>0.112673</td><td>0.102509</td><td>0.905913</td><td>0.871094</td><td>0.119761</td><td>&hellip;</td><td>0.609419</td><td>0.518666</td><td>0.459295</td><td>0.472384</td><td>0.383791</td><td>0.448952</td><td>0.438403</td><td>0.348326</td><td>0.513956</td><td>0.0</td><td>0.497736</td><td>0.534031</td><td>0.551363</td><td>0.536144</td><td>0.403216</td><td>0.462368</td><td>0.511755</td><td>0.458369</td><td>0.407266</td><td>0.317716</td><td>0.516602</td><td>0.402223</td><td>0.465916</td><td>0.547802</td><td>0.439564</td><td>0.378483</td><td>0.438629</td><td>0.317451</td><td>0.376704</td><td>0.385906</td><td>0.378761</td><td>0.398675</td><td>0.274647</td><td>0.32547</td><td>0.336787</td><td>0.348105</td><td>0.316142</td></tr><tr><td>1</td><td>1</td><td>0</td><td>0.01182</td><td>0.339687</td><td>0.049046</td><td>0.0</td><td>0.333914</td><td>0.893082</td><td>0.022523</td><td>0.596433</td><td>0.093691</td><td>0.0</td><td>0.612175</td><td>0.4</td><td>0.634249</td><td>0.699096</td><td>0.764706</td><td>0.661246</td><td>0.121998</td><td>0.135132</td><td>0.345157</td><td>0.141564</td><td>0.337833</td><td>0.052292</td><td>0.287451</td><td>0.1669</td><td>0.151455</td><td>0.145222</td><td>0.017244</td><td>0.101366</td><td>0.043466</td><td>0.096922</td><td>0.098912</td><td>0.905287</td><td>0.891066</td><td>0.094509</td><td>&hellip;</td><td>0.627651</td><td>0.517038</td><td>0.465076</td><td>0.543568</td><td>0.362298</td><td>0.447053</td><td>0.460403</td><td>0.368515</td><td>0.513698</td><td>0.0</td><td>0.483816</td><td>0.525127</td><td>0.549962</td><td>0.617473</td><td>0.394272</td><td>0.478384</td><td>0.495894</td><td>0.453336</td><td>0.407757</td><td>0.282597</td><td>0.513793</td><td>0.430388</td><td>0.54416</td><td>0.616798</td><td>0.415924</td><td>0.383443</td><td>0.443552</td><td>0.311207</td><td>0.408718</td><td>0.404391</td><td>0.3987</td><td>0.417286</td><td>0.345124</td><td>0.359358</td><td>0.421382</td><td>0.416981</td><td>0.416434</td></tr><tr><td>1</td><td>1</td><td>0</td><td>0.01182</td><td>0.532288</td><td>0.065698</td><td>0.0</td><td>0.518635</td><td>0.907757</td><td>0.015015</td><td>0.623074</td><td>0.083666</td><td>0.0</td><td>0.633887</td><td>0.6</td><td>0.558844</td><td>0.699096</td><td>0.75435</td><td>0.649611</td><td>0.115555</td><td>0.112165</td><td>0.350906</td><td>0.144901</td><td>0.53306</td><td>0.064957</td><td>0.305628</td><td>0.268474</td><td>0.14422</td><td>0.12541</td><td>0.011267</td><td>0.100188</td><td>0.04365</td><td>0.07983</td><td>0.094605</td><td>0.904736</td><td>0.906447</td><td>0.083229</td><td>&hellip;</td><td>0.641934</td><td>0.517407</td><td>0.469908</td><td>0.583079</td><td>0.350798</td><td>0.446441</td><td>0.473107</td><td>0.379823</td><td>0.512659</td><td>0.0</td><td>0.477636</td><td>0.521019</td><td>0.552425</td><td>0.656072</td><td>0.388106</td><td>0.482036</td><td>0.489459</td><td>0.452908</td><td>0.407238</td><td>0.270708</td><td>0.512939</td><td>0.446661</td><td>0.589792</td><td>0.649832</td><td>0.407105</td><td>0.385448</td><td>0.447612</td><td>0.309423</td><td>0.42659</td><td>0.413919</td><td>0.413205</td><td>0.426701</td><td>0.389336</td><td>0.371606</td><td>0.469639</td><td>0.462706</td><td>0.479704</td></tr><tr><td>1</td><td>1</td><td>0</td><td>0.052009</td><td>0.782445</td><td>0.09779</td><td>0.0</td><td>0.765703</td><td>0.907112</td><td>0.045738</td><td>0.634082</td><td>0.086217</td><td>0.0</td><td>0.647903</td><td>0.866667</td><td>0.424595</td><td>0.746474</td><td>0.741276</td><td>0.634921</td><td>0.118672</td><td>0.124146</td><td>0.271186</td><td>0.195402</td><td>0.772186</td><td>0.098937</td><td>0.358209</td><td>0.359914</td><td>0.139153</td><td>0.168044</td><td>0.010101</td><td>0.1</td><td>0.037363</td><td>0.076923</td><td>0.08607</td><td>0.91393</td><td>0.897756</td><td>0.102244</td><td>&hellip;</td><td>0.793154</td><td>0.43167</td><td>0.794586</td><td>0.499424</td><td>0.237571</td><td>0.299051</td><td>0.553364</td><td>0.414056</td><td>0.401915</td><td>0.0</td><td>0.389542</td><td>0.45987</td><td>0.473004</td><td>0.623381</td><td>0.388765</td><td>0.551272</td><td>0.526318</td><td>0.410903</td><td>0.328469</td><td>0.180639</td><td>0.43846</td><td>0.462924</td><td>0.530929</td><td>0.610621</td><td>0.382734</td><td>0.38056</td><td>0.376078</td><td>0.291474</td><td>0.415427</td><td>0.478331</td><td>0.3796</td><td>0.435981</td><td>0.361637</td><td>0.377584</td><td>0.49393</td><td>0.543688</td><td>0.402526</td></tr><tr><td>1</td><td>1</td><td>0</td><td>0.040189</td><td>0.714734</td><td>0.091129</td><td>0.0</td><td>0.701614</td><td>0.904088</td><td>0.038288</td><td>0.627477</td><td>0.08704</td><td>0.0</td><td>0.643146</td><td>0.8</td><td>0.424595</td><td>0.746474</td><td>0.713084</td><td>0.603247</td><td>0.124494</td><td>0.13169</td><td>0.367666</td><td>0.195402</td><td>0.771497</td><td>0.098664</td><td>0.341151</td><td>0.338362</td><td>0.147807</td><td>0.187949</td><td>0.010101</td><td>0.1</td><td>0.03956</td><td>0.076923</td><td>0.092008</td><td>0.907992</td><td>0.897936</td><td>0.102064</td><td>&hellip;</td><td>0.801192</td><td>0.612689</td><td>0.589495</td><td>0.797588</td><td>0.233678</td><td>0.535339</td><td>0.485436</td><td>0.366904</td><td>0.532871</td><td>0.0</td><td>0.551965</td><td>0.557861</td><td>0.655238</td><td>0.67948</td><td>0.353477</td><td>0.469403</td><td>0.513295</td><td>0.492052</td><td>0.420313</td><td>0.368434</td><td>0.561858</td><td>0.454755</td><td>0.694326</td><td>0.615664</td><td>0.439867</td><td>0.422545</td><td>0.524813</td><td>0.324633</td><td>0.437919</td><td>0.4458</td><td>0.384594</td><td>0.4275</td><td>0.472736</td><td>0.393942</td><td>0.566841</td><td>0.612135</td><td>0.594258</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 819)\n",
       "┌─────┬────────────┬────────────┬────────────┬───┬────────────┬────────────┬───────────┬───────────┐\n",
       "│ pid ┆ dep_weekly ┆ dep_weekly ┆ f_slp:fitb ┆ … ┆ f_loc:phon ┆ f_wifi:pho ┆ f_wifi:ph ┆ f_wifi:ph │\n",
       "│ --- ┆ subscale_e ┆ subscale_e ┆ it_sleep_s ┆   ┆ e_location ┆ ne_wifi_co ┆ one_wifi_ ┆ one_wifi_ │\n",
       "│ i32 ┆ ndterm_mer ┆ ndterm_mer ┆ ummary_rap ┆   ┆ s_locmap_p ┆ nnected_ra ┆ connected ┆ connected │\n",
       "│     ┆ …          ┆ …          ┆ …          ┆   ┆ …          ┆ …          ┆ _ra…      ┆ _ra…      │\n",
       "│     ┆ ---        ┆ ---        ┆ ---        ┆   ┆ ---        ┆ ---        ┆ ---       ┆ ---       │\n",
       "│     ┆ u8         ┆ u8         ┆ f64        ┆   ┆ f64        ┆ f64        ┆ f64       ┆ f64       │\n",
       "╞═════╪════════════╪════════════╪════════════╪═══╪════════════╪════════════╪═══════════╪═══════════╡\n",
       "│ 1   ┆ 1          ┆ 0          ┆ 0.0        ┆ … ┆ 0.32547    ┆ 0.336787   ┆ 0.348105  ┆ 0.316142  │\n",
       "│ 1   ┆ 1          ┆ 0          ┆ 0.01182    ┆ … ┆ 0.359358   ┆ 0.421382   ┆ 0.416981  ┆ 0.416434  │\n",
       "│ 1   ┆ 1          ┆ 0          ┆ 0.01182    ┆ … ┆ 0.371606   ┆ 0.469639   ┆ 0.462706  ┆ 0.479704  │\n",
       "│ 1   ┆ 1          ┆ 0          ┆ 0.052009   ┆ … ┆ 0.377584   ┆ 0.49393    ┆ 0.543688  ┆ 0.402526  │\n",
       "│ 1   ┆ 1          ┆ 0          ┆ 0.040189   ┆ … ┆ 0.393942   ┆ 0.566841   ┆ 0.612135  ┆ 0.594258  │\n",
       "└─────┴────────────┴────────────┴────────────┴───┴────────────┴────────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rapids_weekly_float.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0a4dd97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 10:47:48,102 - INFO - Created padded sequences with shape: (2360, 819)\n"
     ]
    }
   ],
   "source": [
    "rapids_padded = PreprocessorLSTM.create_padded_sequences(rapids_weekly_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "55e789c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2360,)\n"
     ]
    }
   ],
   "source": [
    "print(np.arange(len(rapids_padded)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8d46ef8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 10:47:54,370 - ERROR - Error splitting data: too many indices for array: array is 1-dimensional, but 2 were indexed\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = PreprocessorLSTM.split_data(rapids_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0d71c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 820)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>pid</th><th>date</th><th>dep_weeklysubscale_endterm_merged_false</th><th>dep_weeklysubscale_endterm_merged_true</th><th>f_slp:fitbit_sleep_summary_rapids_sumdurationafterwakeupmain:14dhist</th><th>f_slp:fitbit_sleep_summary_rapids_sumdurationasleepmain:14dhist</th><th>f_slp:fitbit_sleep_summary_rapids_sumdurationawakemain:14dhist</th><th>f_slp:fitbit_sleep_summary_rapids_sumdurationtofallasleepmain:14dhist</th><th>f_slp:fitbit_sleep_summary_rapids_sumdurationinbedmain:14dhist</th><th>f_slp:fitbit_sleep_summary_rapids_avgefficiencymain:14dhist</th><th>f_slp:fitbit_sleep_summary_rapids_avgdurationafterwakeupmain:14dhist</th><th>f_slp:fitbit_sleep_summary_rapids_avgdurationasleepmain:14dhist</th><th>f_slp:fitbit_sleep_summary_rapids_avgdurationawakemain:14dhist</th><th>f_slp:fitbit_sleep_summary_rapids_avgdurationtofallasleepmain:14dhist</th><th>f_slp:fitbit_sleep_summary_rapids_avgdurationinbedmain:14dhist</th><th>f_slp:fitbit_sleep_summary_rapids_countepisodemain:14dhist</th><th>f_slp:fitbit_sleep_summary_rapids_firstbedtimemain:14dhist</th><th>f_slp:fitbit_sleep_summary_rapids_lastbedtimemain:14dhist</th><th>f_slp:fitbit_sleep_summary_rapids_firstwaketimemain:14dhist</th><th>f_slp:fitbit_sleep_summary_rapids_lastwaketimemain:14dhist</th><th>f_slp:fitbit_sleep_intraday_rapids_avgdurationasleepunifiedmain:14dhist</th><th>f_slp:fitbit_sleep_intraday_rapids_avgdurationawakeunifiedmain:14dhist</th><th>f_slp:fitbit_sleep_intraday_rapids_maxdurationasleepunifiedmain:14dhist</th><th>f_slp:fitbit_sleep_intraday_rapids_maxdurationawakeunifiedmain:14dhist</th><th>f_slp:fitbit_sleep_intraday_rapids_sumdurationasleepunifiedmain:14dhist</th><th>f_slp:fitbit_sleep_intraday_rapids_sumdurationawakeunifiedmain:14dhist</th><th>f_slp:fitbit_sleep_intraday_rapids_countepisodeasleepunifiedmain:14dhist</th><th>f_slp:fitbit_sleep_intraday_rapids_countepisodeawakeunifiedmain:14dhist</th><th>f_slp:fitbit_sleep_intraday_rapids_stddurationasleepunifiedmain:14dhist</th><th>f_slp:fitbit_sleep_intraday_rapids_stddurationawakeunifiedmain:14dhist</th><th>f_slp:fitbit_sleep_intraday_rapids_mindurationasleepunifiedmain:14dhist</th><th>f_slp:fitbit_sleep_intraday_rapids_mindurationawakeunifiedmain:14dhist</th><th>f_slp:fitbit_sleep_intraday_rapids_mediandurationasleepunifiedmain:14dhist</th><th>f_slp:fitbit_sleep_intraday_rapids_mediandurationawakeunifiedmain:14dhist</th><th>f_slp:fitbit_sleep_intraday_rapids_ratiocountasleepunifiedwithinmain:14dhist</th><th>f_slp:fitbit_sleep_intraday_rapids_ratiocountawakeunifiedwithinmain:14dhist</th><th>f_slp:fitbit_sleep_intraday_rapids_ratiodurationasleepunifiedwithinmain:14dhist</th><th>&hellip;</th><th>f_loc:phone_locations_barnett_probpause_norm:7dhist</th><th>f_loc:phone_locations_barnett_rog_norm:7dhist</th><th>f_loc:phone_locations_barnett_siglocentropy_norm:7dhist</th><th>f_loc:phone_locations_barnett_siglocsvisited_norm:7dhist</th><th>f_loc:phone_locations_barnett_stdflightdur_norm:7dhist</th><th>f_loc:phone_locations_barnett_stdflightlen_norm:7dhist</th><th>f_loc:phone_locations_barnett_wkenddayrtn_norm:7dhist</th><th>f_loc:phone_locations_doryab_avglengthstayatclusters_norm:7dhist</th><th>f_loc:phone_locations_doryab_avgspeed_norm:7dhist</th><th>f_loc:phone_locations_doryab_homelabel_norm:7dhist</th><th>f_loc:phone_locations_doryab_locationentropy_norm:7dhist</th><th>f_loc:phone_locations_doryab_locationvariance_norm:7dhist</th><th>f_loc:phone_locations_doryab_loglocationvariance_norm:7dhist</th><th>f_loc:phone_locations_doryab_maxlengthstayatclusters_norm:7dhist</th><th>f_loc:phone_locations_doryab_minlengthstayatclusters_norm:7dhist</th><th>f_loc:phone_locations_doryab_movingtostaticratio_norm:7dhist</th><th>f_loc:phone_locations_doryab_normalizedlocationentropy_norm:7dhist</th><th>f_loc:phone_locations_doryab_numberlocationtransitions_norm:7dhist</th><th>f_loc:phone_locations_doryab_numberofsignificantplaces_norm:7dhist</th><th>f_loc:phone_locations_doryab_outlierstimepercent_norm:7dhist</th><th>f_loc:phone_locations_doryab_radiusgyration_norm:7dhist</th><th>f_loc:phone_locations_doryab_stdlengthstayatclusters_norm:7dhist</th><th>f_loc:phone_locations_doryab_timeathome_norm:7dhist</th><th>f_loc:phone_locations_doryab_timeattop1location_norm:7dhist</th><th>f_loc:phone_locations_doryab_timeattop2location_norm:7dhist</th><th>f_loc:phone_locations_doryab_timeattop3location_norm:7dhist</th><th>f_loc:phone_locations_doryab_totaldistance_norm:7dhist</th><th>f_loc:phone_locations_doryab_varspeed_norm:7dhist</th><th>f_loc:phone_locations_locmap_duration_in_locmap_study_norm:7dhist</th><th>f_loc:phone_locations_locmap_percent_in_locmap_study_norm:7dhist</th><th>f_loc:phone_locations_locmap_duration_in_locmap_exercise_norm:7dhist</th><th>f_loc:phone_locations_locmap_percent_in_locmap_exercise_norm:7dhist</th><th>f_loc:phone_locations_locmap_duration_in_locmap_greens_norm:7dhist</th><th>f_loc:phone_locations_locmap_percent_in_locmap_greens_norm:7dhist</th><th>f_wifi:phone_wifi_connected_rapids_countscans_norm:7dhist</th><th>f_wifi:phone_wifi_connected_rapids_uniquedevices_norm:7dhist</th><th>f_wifi:phone_wifi_connected_rapids_countscansmostuniquedevice_norm:7dhist</th></tr><tr><td>i32</td><td>date</td><td>u8</td><td>u8</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>1</td><td>2018-04-04</td><td>1</td><td>0</td><td>0.0</td><td>0.093041</td><td>0.016954</td><td>0.0</td><td>0.092651</td><td>0.867925</td><td>0.0</td><td>0.490092</td><td>0.097161</td><td>0.0</td><td>0.509579</td><td>0.133333</td><td>0.664553</td><td>0.687161</td><td>0.713582</td><td>0.603806</td><td>0.123021</td><td>0.140463</td><td>0.253021</td><td>0.124989</td><td>0.11734</td><td>0.021833</td><td>0.271134</td><td>0.017449</td><td>0.144736</td><td>0.1521</td><td>0.026507</td><td>0.10324</td><td>0.043685</td><td>0.112673</td><td>0.102509</td><td>0.905913</td><td>0.871094</td><td>&hellip;</td><td>0.609419</td><td>0.518666</td><td>0.459295</td><td>0.472384</td><td>0.383791</td><td>0.448952</td><td>0.438403</td><td>0.348326</td><td>0.513956</td><td>0.0</td><td>0.497736</td><td>0.534031</td><td>0.551363</td><td>0.536144</td><td>0.403216</td><td>0.462368</td><td>0.511755</td><td>0.458369</td><td>0.407266</td><td>0.317716</td><td>0.516602</td><td>0.402223</td><td>0.465916</td><td>0.547802</td><td>0.439564</td><td>0.378483</td><td>0.438629</td><td>0.317451</td><td>0.376704</td><td>0.385906</td><td>0.378761</td><td>0.398675</td><td>0.274647</td><td>0.32547</td><td>0.336787</td><td>0.348105</td><td>0.316142</td></tr><tr><td>1</td><td>2018-04-08</td><td>1</td><td>0</td><td>0.01182</td><td>0.339687</td><td>0.049046</td><td>0.0</td><td>0.333914</td><td>0.893082</td><td>0.022523</td><td>0.596433</td><td>0.093691</td><td>0.0</td><td>0.612175</td><td>0.4</td><td>0.634249</td><td>0.699096</td><td>0.764706</td><td>0.661246</td><td>0.121998</td><td>0.135132</td><td>0.345157</td><td>0.141564</td><td>0.337833</td><td>0.052292</td><td>0.287451</td><td>0.1669</td><td>0.151455</td><td>0.145222</td><td>0.017244</td><td>0.101366</td><td>0.043466</td><td>0.096922</td><td>0.098912</td><td>0.905287</td><td>0.891066</td><td>&hellip;</td><td>0.627651</td><td>0.517038</td><td>0.465076</td><td>0.543568</td><td>0.362298</td><td>0.447053</td><td>0.460403</td><td>0.368515</td><td>0.513698</td><td>0.0</td><td>0.483816</td><td>0.525127</td><td>0.549962</td><td>0.617473</td><td>0.394272</td><td>0.478384</td><td>0.495894</td><td>0.453336</td><td>0.407757</td><td>0.282597</td><td>0.513793</td><td>0.430388</td><td>0.54416</td><td>0.616798</td><td>0.415924</td><td>0.383443</td><td>0.443552</td><td>0.311207</td><td>0.408718</td><td>0.404391</td><td>0.3987</td><td>0.417286</td><td>0.345124</td><td>0.359358</td><td>0.421382</td><td>0.416981</td><td>0.416434</td></tr><tr><td>1</td><td>2018-04-11</td><td>1</td><td>0</td><td>0.01182</td><td>0.532288</td><td>0.065698</td><td>0.0</td><td>0.518635</td><td>0.907757</td><td>0.015015</td><td>0.623074</td><td>0.083666</td><td>0.0</td><td>0.633887</td><td>0.6</td><td>0.558844</td><td>0.699096</td><td>0.75435</td><td>0.649611</td><td>0.115555</td><td>0.112165</td><td>0.350906</td><td>0.144901</td><td>0.53306</td><td>0.064957</td><td>0.305628</td><td>0.268474</td><td>0.14422</td><td>0.12541</td><td>0.011267</td><td>0.100188</td><td>0.04365</td><td>0.07983</td><td>0.094605</td><td>0.904736</td><td>0.906447</td><td>&hellip;</td><td>0.641934</td><td>0.517407</td><td>0.469908</td><td>0.583079</td><td>0.350798</td><td>0.446441</td><td>0.473107</td><td>0.379823</td><td>0.512659</td><td>0.0</td><td>0.477636</td><td>0.521019</td><td>0.552425</td><td>0.656072</td><td>0.388106</td><td>0.482036</td><td>0.489459</td><td>0.452908</td><td>0.407238</td><td>0.270708</td><td>0.512939</td><td>0.446661</td><td>0.589792</td><td>0.649832</td><td>0.407105</td><td>0.385448</td><td>0.447612</td><td>0.309423</td><td>0.42659</td><td>0.413919</td><td>0.413205</td><td>0.426701</td><td>0.389336</td><td>0.371606</td><td>0.469639</td><td>0.462706</td><td>0.479704</td></tr><tr><td>1</td><td>2018-04-18</td><td>1</td><td>0</td><td>0.052009</td><td>0.782445</td><td>0.09779</td><td>0.0</td><td>0.765703</td><td>0.907112</td><td>0.045738</td><td>0.634082</td><td>0.086217</td><td>0.0</td><td>0.647903</td><td>0.866667</td><td>0.424595</td><td>0.746474</td><td>0.741276</td><td>0.634921</td><td>0.118672</td><td>0.124146</td><td>0.271186</td><td>0.195402</td><td>0.772186</td><td>0.098937</td><td>0.358209</td><td>0.359914</td><td>0.139153</td><td>0.168044</td><td>0.010101</td><td>0.1</td><td>0.037363</td><td>0.076923</td><td>0.08607</td><td>0.91393</td><td>0.897756</td><td>&hellip;</td><td>0.793154</td><td>0.43167</td><td>0.794586</td><td>0.499424</td><td>0.237571</td><td>0.299051</td><td>0.553364</td><td>0.414056</td><td>0.401915</td><td>0.0</td><td>0.389542</td><td>0.45987</td><td>0.473004</td><td>0.623381</td><td>0.388765</td><td>0.551272</td><td>0.526318</td><td>0.410903</td><td>0.328469</td><td>0.180639</td><td>0.43846</td><td>0.462924</td><td>0.530929</td><td>0.610621</td><td>0.382734</td><td>0.38056</td><td>0.376078</td><td>0.291474</td><td>0.415427</td><td>0.478331</td><td>0.3796</td><td>0.435981</td><td>0.361637</td><td>0.377584</td><td>0.49393</td><td>0.543688</td><td>0.402526</td></tr><tr><td>1</td><td>2018-04-22</td><td>1</td><td>0</td><td>0.040189</td><td>0.714734</td><td>0.091129</td><td>0.0</td><td>0.701614</td><td>0.904088</td><td>0.038288</td><td>0.627477</td><td>0.08704</td><td>0.0</td><td>0.643146</td><td>0.8</td><td>0.424595</td><td>0.746474</td><td>0.713084</td><td>0.603247</td><td>0.124494</td><td>0.13169</td><td>0.367666</td><td>0.195402</td><td>0.771497</td><td>0.098664</td><td>0.341151</td><td>0.338362</td><td>0.147807</td><td>0.187949</td><td>0.010101</td><td>0.1</td><td>0.03956</td><td>0.076923</td><td>0.092008</td><td>0.907992</td><td>0.897936</td><td>&hellip;</td><td>0.801192</td><td>0.612689</td><td>0.589495</td><td>0.797588</td><td>0.233678</td><td>0.535339</td><td>0.485436</td><td>0.366904</td><td>0.532871</td><td>0.0</td><td>0.551965</td><td>0.557861</td><td>0.655238</td><td>0.67948</td><td>0.353477</td><td>0.469403</td><td>0.513295</td><td>0.492052</td><td>0.420313</td><td>0.368434</td><td>0.561858</td><td>0.454755</td><td>0.694326</td><td>0.615664</td><td>0.439867</td><td>0.422545</td><td>0.524813</td><td>0.324633</td><td>0.437919</td><td>0.4458</td><td>0.384594</td><td>0.4275</td><td>0.472736</td><td>0.393942</td><td>0.566841</td><td>0.612135</td><td>0.594258</td></tr><tr><td>1</td><td>2018-05-02</td><td>1</td><td>0</td><td>0.023641</td><td>0.711724</td><td>0.139873</td><td>0.0</td><td>0.717404</td><td>0.856918</td><td>0.022523</td><td>0.624835</td><td>0.133596</td><td>0.0</td><td>0.65762</td><td>0.8</td><td>0.536998</td><td>0.780108</td><td>0.736654</td><td>0.629729</td><td>0.104387</td><td>0.154175</td><td>0.367666</td><td>0.183908</td><td>0.719667</td><td>0.127283</td><td>0.379531</td><td>0.372845</td><td>0.132202</td><td>0.199157</td><td>0.00505</td><td>0.1</td><td>0.028571</td><td>0.076923</td><td>0.096391</td><td>0.903609</td><td>0.861789</td><td>&hellip;</td><td>0.7435</td><td>0.435432</td><td>0.410851</td><td>0.598812</td><td>0.282515</td><td>0.308321</td><td>0.454431</td><td>0.425334</td><td>0.423559</td><td>0.0</td><td>0.354951</td><td>0.50104</td><td>0.562604</td><td>0.752148</td><td>0.331481</td><td>0.490942</td><td>0.450422</td><td>0.417509</td><td>0.401858</td><td>0.285897</td><td>0.495539</td><td>0.499238</td><td>0.583442</td><td>0.626098</td><td>0.612331</td><td>0.261141</td><td>0.419363</td><td>0.252539</td><td>0.535506</td><td>0.444833</td><td>0.293089</td><td>0.33344</td><td>0.880853</td><td>0.582071</td><td>0.680646</td><td>0.665372</td><td>0.673207</td></tr><tr><td>1</td><td>2018-05-09</td><td>1</td><td>0</td><td>0.016548</td><td>0.75185</td><td>0.125946</td><td>0.0</td><td>0.746198</td><td>0.880987</td><td>0.014553</td><td>0.609288</td><td>0.111041</td><td>0.0</td><td>0.631398</td><td>0.866667</td><td>0.451022</td><td>0.780108</td><td>0.736941</td><td>0.630051</td><td>0.112694</td><td>0.155766</td><td>0.445893</td><td>0.183908</td><td>0.737654</td><td>0.122649</td><td>0.360341</td><td>0.355603</td><td>0.145465</td><td>0.199335</td><td>0.010101</td><td>0.1</td><td>0.028571</td><td>0.076923</td><td>0.094311</td><td>0.905689</td><td>0.86948</td><td>&hellip;</td><td>0.433068</td><td>0.41777</td><td>0.556965</td><td>0.573965</td><td>0.526349</td><td>0.385178</td><td>0.434534</td><td>0.276719</td><td>0.475889</td><td>0.0</td><td>0.516325</td><td>0.486297</td><td>0.541377</td><td>0.526951</td><td>0.331481</td><td>0.3914</td><td>0.535909</td><td>0.440462</td><td>0.380572</td><td>0.262522</td><td>0.465885</td><td>0.333772</td><td>0.594638</td><td>0.639793</td><td>0.408385</td><td>0.336578</td><td>0.363615</td><td>0.24475</td><td>0.446782</td><td>0.578805</td><td>0.330847</td><td>0.417733</td><td>0.680668</td><td>0.673164</td><td>0.599664</td><td>0.574109</td><td>0.675087</td></tr><tr><td>1</td><td>2018-05-13</td><td>1</td><td>0</td><td>0.014184</td><td>0.831348</td><td>0.122616</td><td>0.0</td><td>0.818995</td><td>0.894879</td><td>0.011583</td><td>0.62559</td><td>0.100383</td><td>0.0</td><td>0.643496</td><td>0.933333</td><td>0.451022</td><td>0.670886</td><td>0.722051</td><td>0.613322</td><td>0.117218</td><td>0.14691</td><td>0.445893</td><td>0.195402</td><td>0.844447</td><td>0.126192</td><td>0.396588</td><td>0.387931</td><td>0.153533</td><td>0.19888</td><td>0.010101</td><td>0.1</td><td>0.026374</td><td>0.076923</td><td>0.098361</td><td>0.901639</td><td>0.881843</td><td>&hellip;</td><td>0.646358</td><td>0.53552</td><td>0.453942</td><td>0.723047</td><td>0.318338</td><td>0.362356</td><td>0.582125</td><td>0.335492</td><td>0.497846</td><td>0.0</td><td>0.499208</td><td>0.567387</td><td>0.62263</td><td>0.746287</td><td>0.331481</td><td>0.377691</td><td>0.445087</td><td>0.611333</td><td>0.515384</td><td>0.428742</td><td>0.538771</td><td>0.444174</td><td>0.797206</td><td>0.857544</td><td>0.402567</td><td>0.356577</td><td>0.582149</td><td>0.561927</td><td>0.446782</td><td>0.390272</td><td>0.461271</td><td>0.402246</td><td>0.76079</td><td>0.499902</td><td>0.713469</td><td>0.58932</td><td>0.987123</td></tr><tr><td>1</td><td>2018-05-16</td><td>1</td><td>0</td><td>0.014184</td><td>0.750972</td><td>0.108689</td><td>0.0</td><td>0.738303</td><td>0.896952</td><td>0.012474</td><td>0.608576</td><td>0.095826</td><td>0.0</td><td>0.624718</td><td>0.866667</td><td>0.451022</td><td>0.656058</td><td>0.706593</td><td>0.595954</td><td>0.126933</td><td>0.144894</td><td>0.445893</td><td>0.195402</td><td>0.752194</td><td>0.103025</td><td>0.326226</td><td>0.321121</td><td>0.149839</td><td>0.200203</td><td>0.010101</td><td>0.1</td><td>0.048352</td><td>0.076923</td><td>0.095475</td><td>0.904525</td><td>0.891119</td><td>&hellip;</td><td>0.751048</td><td>0.581439</td><td>0.431507</td><td>0.673353</td><td>0.272707</td><td>0.471796</td><td>0.628249</td><td>0.349088</td><td>0.51426</td><td>0.0</td><td>0.46168</td><td>0.593455</td><td>0.638413</td><td>0.821789</td><td>0.331481</td><td>0.477119</td><td>0.431798</td><td>0.547575</td><td>0.529575</td><td>0.380052</td><td>0.583044</td><td>0.484624</td><td>0.866008</td><td>0.930447</td><td>0.36234</td><td>0.400082</td><td>0.56509</td><td>0.603684</td><td>0.467213</td><td>0.386419</td><td>0.475452</td><td>0.398434</td><td>0.489778</td><td>0.378493</td><td>0.62334</td><td>0.536083</td><td>0.712682</td></tr><tr><td>1</td><td>2018-05-20</td><td>1</td><td>0</td><td>0.021277</td><td>0.735423</td><td>0.096882</td><td>0.0</td><td>0.719726</td><td>0.902758</td><td>0.018711</td><td>0.595976</td><td>0.085416</td><td>0.0</td><td>0.608999</td><td>0.866667</td><td>0.513742</td><td>0.643761</td><td>0.68295</td><td>0.56939</td><td>0.12825</td><td>0.143199</td><td>0.328553</td><td>0.195402</td><td>0.710328</td><td>0.094304</td><td>0.304904</td><td>0.297414</td><td>0.139067</td><td>0.203782</td><td>0.010101</td><td>0.1</td><td>0.043956</td><td>0.076923</td><td>0.099644</td><td>0.900356</td><td>0.89427</td><td>&hellip;</td><td>0.745854</td><td>0.539839</td><td>0.472311</td><td>0.648506</td><td>0.260699</td><td>0.493793</td><td>0.593629</td><td>0.291906</td><td>0.548304</td><td>0.0</td><td>0.50341</td><td>0.570371</td><td>0.624582</td><td>0.708708</td><td>0.331481</td><td>0.507823</td><td>0.443743</td><td>0.527173</td><td>0.52248</td><td>0.363173</td><td>0.573245</td><td>0.414054</td><td>0.763946</td><td>0.821258</td><td>0.357589</td><td>0.380859</td><td>0.482056</td><td>0.2713</td><td>0.470509</td><td>0.433424</td><td>0.416306</td><td>0.404983</td><td>0.409657</td><td>0.351287</td><td>0.496352</td><td>0.505662</td><td>0.458918</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 820)\n",
       "┌─────┬────────────┬────────────┬────────────┬───┬────────────┬────────────┬───────────┬───────────┐\n",
       "│ pid ┆ date       ┆ dep_weekly ┆ dep_weekly ┆ … ┆ f_loc:phon ┆ f_wifi:pho ┆ f_wifi:ph ┆ f_wifi:ph │\n",
       "│ --- ┆ ---        ┆ subscale_e ┆ subscale_e ┆   ┆ e_location ┆ ne_wifi_co ┆ one_wifi_ ┆ one_wifi_ │\n",
       "│ i32 ┆ date       ┆ ndterm_mer ┆ ndterm_mer ┆   ┆ s_locmap_p ┆ nnected_ra ┆ connected ┆ connected │\n",
       "│     ┆            ┆ …          ┆ …          ┆   ┆ …          ┆ …          ┆ _ra…      ┆ _ra…      │\n",
       "│     ┆            ┆ ---        ┆ ---        ┆   ┆ ---        ┆ ---        ┆ ---       ┆ ---       │\n",
       "│     ┆            ┆ u8         ┆ u8         ┆   ┆ f64        ┆ f64        ┆ f64       ┆ f64       │\n",
       "╞═════╪════════════╪════════════╪════════════╪═══╪════════════╪════════════╪═══════════╪═══════════╡\n",
       "│ 1   ┆ 2018-04-04 ┆ 1          ┆ 0          ┆ … ┆ 0.32547    ┆ 0.336787   ┆ 0.348105  ┆ 0.316142  │\n",
       "│ 1   ┆ 2018-04-08 ┆ 1          ┆ 0          ┆ … ┆ 0.359358   ┆ 0.421382   ┆ 0.416981  ┆ 0.416434  │\n",
       "│ 1   ┆ 2018-04-11 ┆ 1          ┆ 0          ┆ … ┆ 0.371606   ┆ 0.469639   ┆ 0.462706  ┆ 0.479704  │\n",
       "│ 1   ┆ 2018-04-18 ┆ 1          ┆ 0          ┆ … ┆ 0.377584   ┆ 0.49393    ┆ 0.543688  ┆ 0.402526  │\n",
       "│ 1   ┆ 2018-04-22 ┆ 1          ┆ 0          ┆ … ┆ 0.393942   ┆ 0.566841   ┆ 0.612135  ┆ 0.594258  │\n",
       "│ 1   ┆ 2018-05-02 ┆ 1          ┆ 0          ┆ … ┆ 0.582071   ┆ 0.680646   ┆ 0.665372  ┆ 0.673207  │\n",
       "│ 1   ┆ 2018-05-09 ┆ 1          ┆ 0          ┆ … ┆ 0.673164   ┆ 0.599664   ┆ 0.574109  ┆ 0.675087  │\n",
       "│ 1   ┆ 2018-05-13 ┆ 1          ┆ 0          ┆ … ┆ 0.499902   ┆ 0.713469   ┆ 0.58932   ┆ 0.987123  │\n",
       "│ 1   ┆ 2018-05-16 ┆ 1          ┆ 0          ┆ … ┆ 0.378493   ┆ 0.62334    ┆ 0.536083  ┆ 0.712682  │\n",
       "│ 1   ┆ 2018-05-20 ┆ 1          ┆ 0          ┆ … ┆ 0.351287   ┆ 0.496352   ┆ 0.505662  ┆ 0.458918  │\n",
       "└─────┴────────────┴────────────┴────────────┴───┴────────────┴────────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rapids_weekly.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18e83401",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = rapids_weekly.select(\"dep_weeklysubscale_endterm_merged_true\").to_numpy().tolist()\n",
    "features = rapids_weekly.to_numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111e7469",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_1 = preprocessor_INS_W1.import_csv_feature_data(\"sleep\")\n",
    "wifi_1 = preprocessor_INS_W1.import_csv_feature_data(\"wifi\")\n",
    "bluetooth_1 = preprocessor_INS_W1.import_csv_feature_data(\"bluetooth\")\n",
    "call_1 = preprocessor_INS_W1.import_csv_feature_data(\"call\")\n",
    "location_1 = preprocessor_INS_W1.import_csv_feature_data(\"location\")\n",
    "screen_1 = preprocessor_INS_W1.import_csv_feature_data(\"screen\")\n",
    "steps_1 = preprocessor_INS_W1.import_csv_feature_data(\"steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f7af79e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_wifi_temp_1 = preprocessor_INS_W1.merge_survey_to_feature(sleep_1, wifi_1, join_type=\"inner\")\n",
    "bluetooth_call_temp_1 = preprocessor_INS_W1.merge_survey_to_feature(bluetooth_1, call_1, join_type=\"inner\")\n",
    "location_screen_temp_1 = preprocessor_INS_W1.merge_survey_to_feature(location_1, screen_1, join_type=\"inner\")\n",
    "\n",
    "sleep_wifi_steps_1 = preprocessor_INS_W1.merge_survey_to_feature(sleep_wifi_temp_1, steps_1, join_type=\"inner\")\n",
    "bluetooth_call_location_screen = preprocessor_INS_W1.merge_survey_to_feature(bluetooth_call_temp_1, location_screen_temp_1, join_type=\"inner\")\n",
    "merged_all_temp = preprocessor_INS_W1.merge_survey_to_feature(sleep_wifi_steps_1, bluetooth_call_location_screen, join_type=\"inner\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
